import pandas as pd
import matplotlib.pyplot as plt
from sklearn.model_selection import train_test_split
from sklearn.linear_model import LinearRegression, Ridge, Lasso
from sklearn.metrics import mean_absolute_error
from sklearn.preprocessing import PolynomialFeatures, StandardScaler
from sklearn.pipeline import make_pipeline
from sklearn.model_selection import cross_val_score

# Load your dataset from a CSV file
# Replace 'your_dataset.csv' with the actual file path and name of your dataset
df = pd.read_csv('/kaggle/input/autompg-dataset/auto-mpg.csv')

# Remove rows with missing horsepower values
df = df[df['horsepower'] != '?']

# Convert the 'Horsepower' column to numeric
df['horsepower'] = pd.to_numeric(df['horsepower'])

# Feature Engineering
df['Engine_Size_Per_Cylinder'] = df['displacement'] / df['cylinders']
df['Power_to_Weight_Ratio'] = df['horsepower'] / df['weight']

# Separate the independent variable (X) and dependent variable (y)
X = df[['horsepower']]  # Independent variable
y = df['mpg']           # Dependent variable

# Split the data into training and testing sets
X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)

# Initialize and train the linear regression model
model = LinearRegression()
model.fit(X_train, y_train)

# Make predictions
y_pred = model.predict(X_test)

# Calculate Mean Absolute Error (MAE) for linear regression
mae = mean_absolute_error(y_test, y_pred)
print('Linear Regression Mean Absolute Error:', mae)

# Polynomial Regression
model_poly = make_pipeline(PolynomialFeatures(degree=2), LinearRegression())
model_poly.fit(X_train, y_train)
y_pred_poly = model_poly.predict(X_test)

# Calculate Mean Absolute Error (MAE) for polynomial regression
mae_poly = mean_absolute_error(y_test, y_pred_poly)
print('Polynomial Regression Mean Absolute Error:', mae_poly)

# Ridge Regression
model_ridge = Ridge(alpha=1.0)
model_ridge.fit(X_train, y_train)
y_pred_ridge = model_ridge.predict(X_test)

# Calculate Mean Absolute Error (MAE) for Ridge regression
mae_ridge = mean_absolute_error(y_test, y_pred_ridge)
print('Ridge Regression Mean Absolute Error:', mae_ridge)

# Lasso Regression
model_lasso = Lasso(alpha=1.0)
model_lasso.fit(X_train, y_train)
y_pred_lasso = model_lasso.predict(X_test)

# Calculate Mean Absolute Error (MAE) for Lasso regression
mae_lasso = mean_absolute_error(y_test, y_pred_lasso)
print('Lasso Regression Mean Absolute Error:', mae_lasso)

# Cross-Validation (Ridge)
ridge_scores = cross_val_score(model_ridge, X, y, cv=5)  # 5-fold cross-validation
print('Ridge Regression Cross-Validation Scores:', ridge_scores)

# Cross-Validation (Lasso)
lasso_scores = cross_val_score(model_lasso, X, y, cv=5)  # 5-fold cross-validation
print('Lasso Regression Cross-Validation Scores:', lasso_scores)

# Visualize Results (Linear Regression)
plt.scatter(X_test, y_test, color='blue', label='Actual')  # Actual data points
plt.scatter(X_test, y_pred, color='red', label='Linear Predicted')  # Linear regression predictions

# Visualize Results (Polynomial Regression)
plt.scatter(X_test, y_pred_poly, color='green', label='Poly Predicted')  # Polynomial regression predictions

plt.xlabel('horsepower')
plt.ylabel('mpg')
plt.title('Actual vs. Predicted MPG by Horsepower')
plt.legend()
plt.grid(True)
plt.show()



